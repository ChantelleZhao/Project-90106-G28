---
title: "Logistic Regression Modeling (Cleaned_3.csv)"
author: "Ziyan Zhao"
date: "02/09/2020"
output: pdf_document
header-includes: \usepackage{color,amsmath}
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lattice)
library(ggplot2)
library(caret)
```

### Attributes:
1: Id	
2: StageName (factor)	
3: Status_Reason__c	
\newline 4: RecordType.Name	
\newline 5: RICE_Supported__c	
6: CreatedDate
\newline 7: AccountId	
8: Lead_Faculty__c
\newline 9: Parent_Opportunity__c (factor) 
\newline 10: RecordType.Name.1 
\newline 11: Industry 
\newline 12: Business_Type__c 
\newline 13: ParentId (factor) 
\newline 14: RecordType 
\newline 15: CreatedDate_month
\newline 16: Is_External__c


```{r,echo=T, eval=T,cache=T, message=F,warning=F}
# Reading Data In
data <- read.csv("/Users/ChantelleChiu/Documents/GitHub/Project-90106-G28/Chantelle/cleaned_3.csv",
                 header = TRUE, stringsAsFactors = T)
names(data) <- c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10",
                 "X11", "X12", "X13", "X14", "X15", "X16") 

#summary(data)
```

Build regression model with 1 predictor ("StageName") and 14 features (X3-X16)
```{r,echo=T, eval=T,cache=T, message=F,warning=F}
mod1 <- glm(factor(X2)~X3+X4+X5+X6+X8+factor(X9)+X10+X11+X12+factor(X13)+X14+X15+X16, 
            family = "binomial", data = data)
```



```{r,echo=T, eval=T,cache=T, message=F,warning=F}

# 10-fold cross_validation
train_control <- trainControl(method = "cv", number = 10)

# train the model on data set
model <- train(factor(X2)~X3+X4+X5+X6+X8+factor(X9)+X10+X11+X12+factor(X13)+X14+X15+X16,
               data = data,
               trControl = train_control,
               method = "glm",
               family="binomial")

# print cv scores
print(model)

# summary(model)
```
## Conclusion:
Accuracy 99%
No attributes are significant (p-value < 0.05)

### Next step:
Remove feature X3: "Status_Reason__c"
Build regression model with 1 predictor ("StageName") and 13 features (X4-X16)
```{r,echo=T, eval=T,cache=T, message=F,warning=F}
mod2 <- glm(factor(X2)~X4+X5+X6+X8+factor(X9)+X10+X11+X12+factor(X13)+X14+X15+X16, 
            family = "binomial", data = data)
```


```{r,echo=T, eval=T,cache=T, message=F,warning=F}
# 10-fold cross_validation
train_control <- trainControl(method = "cv", number = 10)

# train the model on data set
model <- train(factor(X2)~X4+X5+X6+X8+factor(X9)+X10+X11+X12+factor(X13)+X14+X15+X16,
               data = data,
               trControl = train_control,
               method = "glm",
               family="binomial")
```


```{r,echo=T, eval=T,cache=T, message=F,warning=F}
summary(model)
```
## Conclusion:

### Recall the attributes:
1: Id	
2: StageName (factor)	
3: Status_Reason__c	
\newline 4: RecordType.Name	
\newline 5: RICE_Supported__c	
6: CreatedDate
\newline 7: AccountId	
8: Lead_Faculty__c
\newline 9: Parent_Opportunity__c (factor) 
\newline 10: RecordType.Name.1 
\newline 11: Industry 
\newline 12: Business_Type__c 
\newline 13: ParentId (factor) 
\newline 14: RecordType 
\newline 15: CreatedDate_month
\newline 16: Is_External__c


### Significant Attributes:

### Very significant (p-value < 0.001): 
  X4Competitive Bid
  \newline X4Parent Grant
  \newline X5RIC RE&D and BD&I
  \newline X5RIC-BD&I
  \newline X6
  \newline X80012e000002ZFZYAA4
  \newline X80012e000002ZGfbAAG         
  X80012e000002ZLg7AAG         
  X80012e000002ZLgIAAW         
  X80012e000002ZLgJAAW         
  X80012e000002ZmnxAAC         
  X80012e000002ZmnzAAC          
  X80012e000002Zmo0AAC         
  X80012e000002ZmOUAA0         
  X80012e000002ZmOZAA0         
  X80012e000002ZNYOAA4
  X80012e000002Zt1iAAC
  X80012e000002Zt1RAAS
  
### Significant (0,001 < p-value < 0.01)
  X4Sponsorship
  \newline X4Technology Transfer
  \newline X5RIC-RE&D
  \newline factor(X9)1
  \newline X12PFRO (Publicly-Funded Research Organisation)
  
### Somehow significant (0.01 < p-value < 0.05)
  X4Panel
  \newline X4Philanthropic
  \newline X4Sponsorship
  \newline X12Multinational / Other Large Corporate
  \newline X12Not for profit
  
### 0.05 < p-value < 0.1 (keep or not?)
  X12University
  \newline X13
  \newline X15


```{r,echo=T, eval=T,cache=T, message=F,warning=F}
print(model)
```
## Conclusion
1. Accuracy drops from 99% to around 73%.
\newline 2. Since we have about 2:1 split for classes 0 and 1 of the "stageName", which is sort of imbalance, we might also want to look at the Kappa accuracy which is nearly 38%. According to the guideline for Kappa score, 38% is a high "fair".

## Note
from website
https://machinelearningmastery.com/machine-learning-evaluation-metrics-in-r/

### Accuracy 
is the percentage of correctly classifies instances out of all instances. It is more useful on a binary classification than multi-class classification problems because it can be less clear exactly how the accuracy breaks down across those classes.

### Kappa or Cohen’s Kappa 
is like classification accuracy, except that it is normalized at the baseline of random chance on your dataset. It is a more useful measure to use on problems that have an imbalance in the classes (e.g. 70-30 split for classes 0 and 1 and you can achieve 70% accuracy by predicting all instances are for class 0).

### Suggested guidelines for Kappa:
values <= 0 as indicating no agreement 
\newline 0.01–0.20 as none to slight
\newline 0.21–0.40 as fair, 0.41– 0.60 as moderate,
\newline 0.61–0.80 as substantial
\newline 0.81–1.00 as almost perfect agreement.